{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=\"7\"> Captcha Solver with Deep Learning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CAPTCHA has become an important issue in multimedia security. CAPTCHAs were designed to prevent computers from automatically filling out forms by verifying that you are a real person. But with the rise of deep learning and computer vision, they can now often be defeated easily. \n",
    "\n",
    "<br />\n",
    "<div>\n",
    "<img src=\"notebookImages/ANeuralNetwork.jfif\" width=\"500\"/>\n",
    "</div>\n",
    "<br />\n",
    "\n",
    "In this notebook, we implement CAPTCHA image recognition and prediction. We study the use of a Deep Learning algorithm- Convolutional Neural Network in CAPTCHA recognition. We also use simpler classification algorithms- Randomn Forest and K-Nearest Neighbours. The accuracy of each is compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 4-letter CAPTCHAs using a random mix of four different fonts. The CAPTCHAs have both alphabets and numbers. Our training data has 10,000 PNG files with the correct answer for each as the filename.\n",
    "Here is what it looks like-\n",
    "\n",
    "<br />\n",
    "<div>\n",
    "<img src=\"notebookImages/aLookAtTheDataset.PNG\" width=\"500\"/>\n",
    "</div>\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the CAPTCHA images are always made of 4 alphanumeric characters. We will split the CAPTCHA such that each letter is a separate image. This way, we only have to train the neural network to recognize a single letter at a time. Hence we extract different variations of each letter into another folder. Here's a look at that folder-\n",
    "\n",
    "<br />\n",
    "<div>\n",
    "<img src=\"notebookImages/Rletter.PNG\" width=\"500\"/>\n",
    "</div>\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this segment, we will read in input captcha, do some image procesing to detect 4 regions within the CAPTCHA and save separate images of the characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'Importing required packages'\n",
    "\n",
    "import cv2\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class containing Image Processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Resize the image - Depending on whichever is greater, height or width, we resize along that side and then we pad the image. Padding is the space between an image or cell contents and its outside border.\n",
    "2. Image Tresholding - Image thresholding is a simple form of image segmentation. It is a way to create a binary image from a grayscale or full-color image. This is done in order to separate \"object\" or foreground pixels from background pixels. This makes it easy to find the continous regions. \n",
    "3. Finding Regions - We use OpenCVâ€™s findContours() function to detect the separate parts of the image that contain continuous blobs of pixels of the same color.\n",
    "4. We then save each region as a separate image file maintaing the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class captcha_breaker:\n",
    "    \n",
    "    def resizeImg(image, width, height):\n",
    "        (imgH, imgW) = image.shape[:2]\n",
    "        if imgW > imgH:\n",
    "            image = imutils.resize(image, width=width)\n",
    "        else:\n",
    "            image = imutils.resize(image, height=height) \n",
    "        newW = int((width - image.shape[1]) / 2.0)\n",
    "        newH = int((height - image.shape[0]) / 2.0)\n",
    "        image = cv2.copyMakeBorder(image, newH, newH, newW, newW,\n",
    "            cv2.BORDER_REPLICATE)\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def processImg(img):    \n",
    "        imgBorder = cv2.copyMakeBorder(img, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
    "        ret, imgThreshold = cv2.threshold(imgBorder, 127, 255, cv2.THRESH_BINARY)\n",
    "        kernel = np.ones((1,2), np.uint8)\n",
    "        imgErode = cv2.erode(imgThreshold, kernel, iterations = 1)\n",
    "        return imgErode\n",
    "    \n",
    "    \n",
    "    def getImgRegion(imgErode):\n",
    "        contours = cv2.findContours(imgErode, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = contours[0]\n",
    "        imageRegions = []\n",
    "        areaArr = []\n",
    "\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            areaArr.append(area)\n",
    "        median = 0\n",
    "        areaArr.sort()\n",
    "        if len(areaArr)%2 != 0:\n",
    "            mid = int(len(areaArr)/2)\n",
    "            median = areaArr[mid]\n",
    "        else:\n",
    "            mid = int(len(areaArr)/2)\n",
    "            median = (areaArr[mid] + areaArr[mid - 1])/2\n",
    "\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 3*median or area < median/3:\n",
    "                continue;\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            imgRGB = cv2.cvtColor(imgErode,cv2.COLOR_GRAY2RGB)\n",
    "            if w/h > 1.25:\n",
    "                half_width = int(w/2)\n",
    "                imageRegions.append((x, y, half_width, h))\n",
    "                imageRegions.append((x + half_width, y, half_width, h))\n",
    "            else:\n",
    "                imageRegions.append((x, y, w, h))\n",
    "\n",
    "        imageRegions = sorted(imageRegions, key=lambda x: x[0])\n",
    "        return imageRegions\n",
    "    \n",
    "    def printRegions(imageRegions):\n",
    "        for point in imageRegions:    \n",
    "            imgRGB = cv2.cvtColor(imgErode, cv2.COLOR_GRAY2RGB)\n",
    "            imgRect = cv2.rectangle(imgRGB, (point[0], point[1]), (point[0]+point[2], point[1]+point[3]), (255,0,0), 1)\n",
    "\n",
    "            plt.imshow(imgRect)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to try it on some data.\n",
    "This is going to be done in three parts:\n",
    "I. Processing the CAPTCHA\n",
    "II. CAPTCHA prediction using Neural Network\n",
    "III. Randomn Forest and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Processing the CAPTCHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Tresholding - To increase the quality of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Input a test CAPTCHA. Perform Image Tresholding'\n",
    "\n",
    "cb = captcha_breaker\n",
    "img = cv2.imread(\"tests/01.png\", 0)\n",
    "imgErode = cb.processImg(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Regions - To find separate parts of the image that contain continuous blobs of pixels of the same color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADnElEQVR4nO3d0W7aQABFwbrK//8yfa0cBXdr+9hmZ16pEgLoaLm1YHm9Xr8AaPy++g4AzER0AUKiCxASXYCQ6AKERBcg9LVxu+vJAMYtP93gpAsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCX1ffAeAYy7L88799vV4n3hPecdIFCIkuQEh0AULzbboDu9ej2Og+3shmy3056QKERBcgJLoAofk23bXBLfSsXW34ukn73nTWr5HR16Jrc+/BSRcgJLoAIdEFCE2/6e7ZaPdubBznysfeVsoIJ12AkOgChKafF7a8e+u49y3tXd6WHvnW/Kq/6czLqbZ+1vr2uzyv3JOTLkBIdAFCogsQsumyaw8d2S+3fu7Wz3JJ3j5/P3525+s46QKERBcgJLoAoek33XLbmnFHO+sa4DvtuzM+r/w/J12AkOgChEQXIDT9pjvqTlvip7nyMww8r1ScdAFCogsQEl2AkE2XQ525jd51d/V5uoxw0gUIiS5AyLyw4chvC+Y8Z35dz9rI1/d4DbDmpAsQEl2AkOgChGy67DLyFTyjO+tdLxGDPZx0AUKiCxASXYCQTfdAo9dkvtssXd/53pWPz95rgpmbky5ASHQBQqILELLprtxln3vqxwXe5X6eubve5TUy6i7PzeycdAFCogsQEl2AkE33QEduffa37858TN59Bu6Zn83LfJx0AUKiCxASXYCQTfdAM255d/2b9+zrT71Geu2p9/vTOekChEQXIGReWPGW7L09j8/opVhH/q6n2DOLPPVvno2TLkBIdAFCogsQsuk+9GP6zmQbvI7H/vM56QKERBcgJLoAoWVjQzIwAYz78T+LnHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyD0tXH7ktwLgEk46QKERBcgJLoAIdEFCIkuQEh0AUJ/APqMpllBxxo2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADlUlEQVR4nO3d0a6aQBRA0dr4/79sXxvMxU6BDThrvdprEczOcDLBx+v1+gVA4/fZBwAwE9EFCIkuQEh0AUKiCxASXYDQ88Pr9pMBjHv89IKVLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQg9zz4AYB+Px+Of/+3r9TrwSFhjpQsQEl2AkOgChMx04SZGZrZcl5UuQEh0AUKiCxAy0x101Fwt3Tf5DbPBCfeZLr8jo99Fe3OvwUoXICS6ACHRBQhNP9PdMqPdOmO7jLvM+lbO75nn3qyUEVa6ACHRBQhNP174ZO3Wcest7VVuS/e8NT/rMx25nerTey1fv8p15ZqsdAFCogsQEl2AkJkum+ahI/PLT++753vx7u9zZu58HitdgJDoAoREFyA0/Uy3nG3NOEebYfY643Xl/1npAoREFyAkugCh6We6o2aYUZ7lzGcYuK5UrHQBQqILEBJdgJCZLruacTbqebqMsNIFCIkuQMh44YM9fy2Y4xz5cz1LIz/f4zvAkpUuQEh0AUKiCxAy02WTkZ/gGZ2zvm3FGvpruCYrXYCQ6AKERBcgZKa7o9E9mWszTvs71515frbuCWZuVroAIdEFCIkuQMhMd+Eq87m7Pi7wKsd55Nz1Kt+RUVe5NrOz0gUIiS5ASHQBQma6O9pz1mf+1lp7Bu6Rz+ZlPla6ACHRBQiJLkDITHdHM87yrvqZt8zX77pHeumux/3trHQBQqILEDJeWHBLtm7L+RndivX2fw2MDO56HbeMRe76mWdjpQsQEl2AkOgChMx0eWM2eB7n/vtZ6QKERBcgJLoAITNdTmN+yYysdAFCogsQEl2AkJkuQ880ALax0gUIiS5ASHQBQma6M7I/Fk5jpQsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6AKHnh9cfyVEATMJKFyAkugAh0QUIiS5ASHQBQqILEPoDRdWiX2AEnlYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADl0lEQVR4nO3d0Y6aUBRA0drM//+yfW0xxbkDbMC71qsdi0J2jidEH8/n8xcAjd9nHwDATEQXICS6ACHRBQiJLkBIdAFCX28edz8ZwLjH/x4w6QKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYDQ19kHAOzj8Xh8+98+n88Dj4Q1Jl2AkOgChEQXIGSnCzcxsrPluky6ACHRBQiJLkDITnfQUXs1901+wyfsNDec5+U1MnotusauwaQLEBJdgJDoAoSm3+lu2dFu3bGxwYXe+9VdqWuCBZMuQEh0AULTrxfeWfvouPUj7VVu4dnzo/lZr+nI26nePdfy8aucV67JpAsQEl2AkOgChOx02bQPHdlfvnvePZ+LV3+/Z/bO5zHpAoREFyAkugCh6Xe65W5rxj3aDLvXGc8rP2fSBQiJLkBIdAFC0+90R82wozzLmd9h4LxSMekChEQXICS6ACE7XXY1427U9+kywqQLEBJdgJD1wht7/lowxzny53qWRn6+xxXAkkkXICS6ACHRBQjZ6bLJyE/wjO5ZX27FGvpruCaTLkBIdAFCogsQstPd0eh9uWs7Tvf4rjvz/dl6TzBzM+kChEQXICS6ACE73YWr7Ofu+nWBVznOI/euV7lGRl3l3MzOpAsQEl2AkOgChOx0d7Tnrs/+rfXPd+Du+d28N93/chyTLkBIdAFCogsQstPd0Yx72Ku+5i379bveI7101+P+dCZdgJDoAoSsFxZ8JFu35f0ZvRXr5f8aWBnc9TxuWYvc9TXPxqQLEBJdgJDoAoTsdHlhN3ge7/3nM+kChEQXICS6ACE7XU5jf8mMTLoAIdEFCIkuQMhOl3vyMzjclEkXICS6ACHRBQjZ6XIf7uvlA5h0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcg9PXm8UdyFACTMOkChEQXICS6ACHRBQiJLkBIdAFCfwAzD6Bj4ddR7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADn0lEQVR4nO3dW47aQAAF0RDN/rdMfiNPAunYLrfpc36RZnip1FxZ8Hg+nz8AaPy8+g4ArER0AUKiCxASXYCQ6AKERBcg9PXmdteTAYx7/O0GJ12AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6AKGvq+8ALO3xuPoe/NnzefU9+FhOugAh0QUIiS5AyKYLM9mxpT4G9uHn9v/Mui1/ICddgJDoAoREFyBk04WbGNlsmZeTLkBIdAFCogsQsukOOmtX+3bdJGxs3yOj70XvsTk46QKERBcgJLoAoeU33T0b7d6NjeNc+dzbShnhpAsQEl2A0PLzwjuvPjru/Ug7y8fSIz+aX/WYzryc6t3f2t4+y+vKnJx0AUKiCxASXYCQTZdde+jIfvnu7777Wy7J2+f358/ufB0nXYCQ6AKERBcgtPymW25bK+5oZ10DPNO+u+Lryv9z0gUIiS5ASHQBQstvuqNm2hI/zZXfYeB1peKkCxASXYCQ6AKEbLoc6sxtdNbd1ffpMsJJFyAkugAh88IbR/5aMOc58+d6tkZ+vsd7gC0nXYCQ6AKERBcgZNNll5Gf4BndWWe9RAz2cNIFCIkuQEh0AUI23QONXpP5arN0fedrVz4/e68JZm1OugAh0QUIiS5AyKa7Mcs+d9evC5zlfp65u87yHhk1y2uzOiddgJDoAoREFyBk0z3QkVuf/e27M5+TV9+Be+Z387IeJ12AkOgChEQXIGTTPdCKW96sj3nPvn7Xa6S37nq/P52TLkBIdAFC5oUNH8le2/P8jF6KdeT/uos9s8hdH/NqnHQBQqILEBJdgJBNl29sg9fx3H8+J12AkOgChEQXIGTT5TL2yz+46U8B8e+cdAFCogsQEl2AkE0XrmTXXo6TLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkDo683tj+ReACzCSRcgJLoAIdEFCIkuQEh0AUKiCxD6BaRjp140IWy2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageRegions = cb.getImgRegion(imgErode)\n",
    "cb.printRegions(imageRegions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the data - Find and save as separate alphanumeric value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting single letter images and saving it in a folder called data_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing\n"
     ]
    }
   ],
   "source": [
    "FOLDER_INPUT = \"CAPTCHA_IMGS\"\n",
    "FOLDER_OUTPUT = \"Single_letters\"\n",
    "captchaImgs = glob.glob(os.path.join(FOLDER_INPUT, \"*\"))\n",
    "countLetter = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "countNumber = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for i, file in enumerate(captchaImgs):\n",
    "    name = os.path.basename(file)\n",
    "    captchaText = os.path.splitext(name)[0]\n",
    "    pathImg = \"CAPTCHA_IMGS/\" + name  \n",
    "    img = cv2.imread(pathImg, 0)   \n",
    "    imgErode = cb.processImg(img)\n",
    "    \n",
    "    imageRegions = cb.getImgRegion(imgErode)\n",
    "    if len(imageRegions) != 4:\n",
    "        continue;\n",
    "        \n",
    "    for points, letter in zip(imageRegions, captchaText):\n",
    "        x, y, w, h = points\n",
    "        \n",
    "        imageSave = imgErode[y:y + h, x:x + w]\n",
    "\n",
    "        pathSave = os.path.join(FOLDER_OUTPUT, letter)\n",
    "    \n",
    "        if not os.path.exists(pathSave):\n",
    "            os.makedirs(pathSave)\n",
    "        \n",
    "        ans = ord(letter)\n",
    "\n",
    "        if ans >= 0 and ans < ord('A'):\n",
    "            idx = ans - ord('0')\n",
    "            countNumber[idx] = countNumber[idx] + 1\n",
    "            strImgPath = str(countNumber[idx]) + \".png\"\n",
    "        else:\n",
    "            idx = ans - ord('A')\n",
    "            countLetter[idx] = countLetter[idx] + 1\n",
    "            strImgPath = str(countLetter[idx]) + \".png\"\n",
    "        \n",
    "        pt = os.path.join(pathSave, strImgPath)\n",
    "        cv2.imwrite(pt, imageSave)\n",
    "\n",
    "print(\"finish processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. CAPTCHA prediction with Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish append\n"
     ]
    }
   ],
   "source": [
    "FOLDER_LETTERS_INPUT = \"Single_letters\"\n",
    "\n",
    "dataImages = []\n",
    "dataLabels = []\n",
    "\n",
    "for file in paths.list_images(FOLDER_LETTERS_INPUT):\n",
    "    image = cv2.imread(file, 0)\n",
    "    image = cb.resizeImg(image, 20, 20)\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    label = file.split(os.path.sep)[-2]\n",
    "    \n",
    "    dataImages.append(image)\n",
    "    dataLabels.append(label)\n",
    "\n",
    "print(\"finish append\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n"
     ]
    }
   ],
   "source": [
    "print(dataLabels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34832\n",
      "34832\n"
     ]
    }
   ],
   "source": [
    "print(len(dataImages))\n",
    "print(len(dataLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LABELS_MODEL = \"label_model.dat\"\n",
    "\n",
    "dataImages = np.array(dataImages)/255\n",
    "dataLabels = np.array(dataLabels)\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "dataLabels = encoder.fit_transform(dataLabels)\n",
    "\n",
    "(Xtrain, Xtest, Ytrain, Ytest) = train_test_split(dataImages, dataLabels, test_size=0.25, random_state=70)\n",
    "\n",
    "with open(FILE_LABELS_MODEL, \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = \"model.hdf5\"\n",
    "\n",
    "main_model = Sequential()\n",
    "\n",
    "main_model.add(Conv2D(20, (2, 2), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n",
    "main_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "main_model.add(Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\"))\n",
    "main_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "main_model.add(Flatten())\n",
    "main_model.add(Dense(500, activation=\"relu\"))\n",
    "\n",
    "main_model.add(Dense(32, activation=\"softmax\"))\n",
    "\n",
    "main_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adagrad\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 20)        100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        5184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               800500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                16032     \n",
      "=================================================================\n",
      "Total params: 821,816\n",
      "Trainable params: 821,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "main_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26124 samples, validate on 8708 samples\n",
      "Epoch 1/10\n",
      "26124/26124 [==============================] - 11s 430us/step - loss: 0.2196 - accuracy: 0.9492 - val_loss: 0.0570 - val_accuracy: 0.9905\n",
      "Epoch 2/10\n",
      "26124/26124 [==============================] - 11s 422us/step - loss: 0.0441 - accuracy: 0.9928 - val_loss: 0.0423 - val_accuracy: 0.9918\n",
      "Epoch 3/10\n",
      "26124/26124 [==============================] - 11s 406us/step - loss: 0.0313 - accuracy: 0.9945 - val_loss: 0.0356 - val_accuracy: 0.9930\n",
      "Epoch 4/10\n",
      "26124/26124 [==============================] - 11s 430us/step - loss: 0.0236 - accuracy: 0.9957 - val_loss: 0.0336 - val_accuracy: 0.9929\n",
      "Epoch 5/10\n",
      "26124/26124 [==============================] - 11s 421us/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.0322 - val_accuracy: 0.9935\n",
      "Epoch 6/10\n",
      "26124/26124 [==============================] - 10s 395us/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 0.0310 - val_accuracy: 0.9941\n",
      "Epoch 7/10\n",
      "26124/26124 [==============================] - 10s 386us/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.0305 - val_accuracy: 0.9938\n",
      "Epoch 8/10\n",
      "26124/26124 [==============================] - 10s 384us/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.0304 - val_accuracy: 0.9938\n",
      "Epoch 9/10\n",
      "26124/26124 [==============================] - 11s 405us/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.0285 - val_accuracy: 0.9946\n",
      "Epoch 10/10\n",
      "26124/26124 [==============================] - 10s 381us/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0284 - val_accuracy: 0.9946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa1c6aaea90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_model.fit(Xtrain, Ytrain, validation_data=(Xtest, Ytest), batch_size=32, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model.save(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction class (for CNN, Random forest, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class captcha_predict:\n",
    "    def CNNpredictImage(img):\n",
    "        dataImagesPredict = []\n",
    "\n",
    "        imgErode = cb.processImg(img)\n",
    "        imageRegions = cb.getImgRegion(imgErode)\n",
    "\n",
    "        for points in imageRegions:\n",
    "            x, y, w, h = points\n",
    "\n",
    "            image = imgErode[y:y + h, x:x + w]\n",
    "\n",
    "            image = cb.resizeImg(image, 20, 20)\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "\n",
    "            dataImagesPredict.append(image)\n",
    "\n",
    "        dataImagesPredict = np.array(dataImagesPredict)/255\n",
    "\n",
    "        for element in dataImagesPredict:\n",
    "            prediction = main_model.predict(dataImagesPredict)\n",
    "            letter = encoder.inverse_transform(prediction)\n",
    "            \n",
    "        print(\"CAPTCHA TEXT:\", letter)\n",
    "        plt.imshow(imgErode, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    def rfPredict(img):\n",
    "        dataImagesPredict = []\n",
    "\n",
    "        imgErode = cb.processImg(img)\n",
    "        imageRegions = cb.getImgRegion(imgErode)\n",
    "\n",
    "        for points in imageRegions:\n",
    "            x, y, w, h = points\n",
    "\n",
    "            image = imgErode[y:y + h, x:x + w]\n",
    "\n",
    "            image = cb.resizeImg(image, 20, 20)\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "\n",
    "            dataImagesPredict.append(image)\n",
    "\n",
    "        dataImagesPredict = np.array(dataImagesPredict)/255\n",
    "        print(dataImagesPredict.shape)\n",
    "        \n",
    "        a, b, c, d = dataImagesPredict.shape\n",
    "        dataImagesPredict = dataImagesPredict.reshape((a,b*c*d))\n",
    "\n",
    "        for element in dataImagesPredict:\n",
    "            prediction = rf.predict(dataImagesPredict)\n",
    "            letter = encoder.inverse_transform(prediction)\n",
    "            \n",
    "        print(\"CAPTCHA TEXT:\", letter)\n",
    "        plt.imshow(imgErode, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    def knnPredict(img):\n",
    "        dataImagesPredict = []\n",
    "\n",
    "        imgErode = cb.processImg(img)\n",
    "        imageRegions = cb.getImgRegion(imgErode)\n",
    "\n",
    "        for points in imageRegions:\n",
    "            x, y, w, h = points\n",
    "\n",
    "            image = imgErode[y:y + h, x:x + w]\n",
    "\n",
    "            image = cb.resizeImg(image, 20, 20)\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "\n",
    "            dataImagesPredict.append(image)\n",
    "\n",
    "        dataImagesPredict = np.array(dataImagesPredict)/255\n",
    "        print(dataImagesPredict.shape)\n",
    "        \n",
    "        a, b, c, d = dataImagesPredict.shape\n",
    "        dataImagesPredict = dataImagesPredict.reshape((a,b*c*d))\n",
    "\n",
    "        for element in dataImagesPredict:\n",
    "            prediction = knn.predict(dataImagesPredict)\n",
    "            letter = encoder.inverse_transform(prediction)\n",
    "            \n",
    "        print(\"CAPTCHA TEXT:\", letter)\n",
    "        plt.imshow(imgErode, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAPTCHA Prediction with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPTCHA TEXT: ['Z' 'W' 'B' 'J']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADhklEQVR4nO3d0W6bQBRAwVL5/3/Zfa0cxXQLHNbZmVdHFgF0tFyt8PZ8Pn8B0Ph99wEArER0AUKiCxASXYCQ6AKERBcg9Nj53H4ygHHbdx9Y6QKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYDQ4+4DAM6xbds//+3z+bzwSHjHShcgJLoAIdEFCJnpwocYmdkyLytdgJDoAoREFyBkpjvoqrmafZPseb1HRu9F99gcrHQBQqILEBJdgNDyM90jM9qjMzbOc+e5NytlhJUuQEh0AULLjxf2vHt0PPpIO8tj6ZmP5nf9T1dup9r7rtfPZ7muzMlKFyAkugAh0QUImelyaB46Mr/c+96977Il75i/z5+5832sdAFCogsQEl2A0PIz3XK2teIc7ao9wDPNd1e8rvw/K12AkOgChEQXILT8THfUTLPEn+bOdxi4rlSsdAFCogsQEl2AkJkup7pyNjrr3NX7dBlhpQsQEl2AkPHCjjN/LZjrXPlzPa9Gfr7HPcArK12AkOgChEQXIGSmyyEjP8EzOmeddYsYHGGlCxASXYCQ6AKEzHRPNLon893M0v7O9+48P0f3BLM2K12AkOgChEQXIGSm+2KW+dynvi5wluO8cu46yz0yapZrszorXYCQ6AKERBcgZKZ7ojNnfeZvX115Tt69A/fKd/OyHitdgJDoAoREFyBkpnuiFWd5s/7PR+brn7pH+tWnHvdPZ6ULEBJdgNC28wji+WRB1SsnR37qZxVHxiIrnq+JfXshrXQBQqILEBJdgJAtY3xhNngf5/7ns9IFCIkuQEh0AUJmutzG/JIVWekChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkDosfP5lhwFwCKsdAFCogsQEl2AkOgChEQXICS6AKE/fRecYBpzceUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPTCHA TEXT: ['C' 'G' 'L' 'T']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADWElEQVR4nO3d207CQBRAUWr4/1+urwqRpnbY9LLWK4G0BXfG41SmeZ5vADS+Pn0AAFciugAh0QUIiS5ASHQBQqILELovPG4/GcB6018PWOkChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQjdP30A8AnTNP37ufM8DzwSrsZKFyAkugAh0QUImemGzBH34/F6bnlvYA0rXYCQ6AKERBcgZKY70Nq54Ks57eNrLb22me/7HPXaVnPqo16fT7HSBQiJLkDIeGGDkeOEvXrnr6hHvB5nMXLL3BV+Dkay0gUIiS5ASHQBQma6K11hG86rc1w6ri3PLV3htt8113vtjHfNdkd+s9IFCIkuQEh0AUJmum+0pxnmKyPnsEc5Z34bOYf1GXjNShcgJLoAIdEFCIkuQEh0AUKiCxASXYCQfboLzngf+RnPCY7CShcgJLoAIeMFnriNk0c+E+NY6QKERBcgJLoAITPdBSO/qvqM/EtAWMdKFyAkugAh0QUImem+0eO884wzyy0z7zNej9vtGF9D728Tn2OlCxASXYCQ6AKEzHRX+jmTWzsXO8qe1p/HufUr2PcyO9xyHHs5B87BShcgJLoAIdEFCJnpblDOL/eyv/OoRl4/e5HZwkoXICS6ACHRBQhNCzMnA6kLGDmjNO/cry1/c/BerfbnxbbSBQiJLkDIeIEnR7ldGXbMeAFgD0QXICS6ACG3AfPEHBbex0oXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXIHRfeHxKjgLgIqx0AUKiCxASXYCQ6AKERBcgJLoAoW//LYtX6vC1JAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cp = captcha_predict\n",
    "\n",
    "img = cv2.imread(\"tests/01.png\", 0)\n",
    "cp.CNNpredictImage(img)\n",
    "\n",
    "img = cv2.imread(\"tests/02.png\", 0)\n",
    "cp.CNNpredictImage(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tested our model with 2 test cases. In both cases, the CAPTCHA text and the image matches.\n",
    "\n",
    "We will now use Rondom Forest and KNN algorithms and see how they fare compared to CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Randomn Forest and KNN Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26124, 400)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape\n",
    "a, b, c, d = Xtrain.shape\n",
    "XtrainNew = Xtrain.reshape((a,b*c))\n",
    "XtrainNew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8708, 400)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape\n",
    "a, b, c, d = Xtest.shape\n",
    "XtestNew = Xtest.reshape((a,b*c*d))\n",
    "XtestNew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26124, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomn Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, X, y):\n",
    "  model.fit(X,y)\n",
    "  \n",
    "  return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "                            criterion='gini', \n",
    "                            max_features='sqrt',\n",
    "                            n_jobs=-1)\n",
    "model_training(rf, XtrainNew, Ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.00%\n",
      "Test accuracy: 99.94%\n"
     ]
    }
   ],
   "source": [
    "def get_acuuracy(model, X, y):\n",
    "  y_pred = model.predict(X)\n",
    "\n",
    "  if sys.version_info < (3, 0):\n",
    "      accuracy = ((np.sum(y == y_pred, axis=0)).astype('float') /\n",
    "            X.shape[0])\n",
    "  else:\n",
    "      accuracy = np.sum(y == y_pred, axis=0) / X.shape[0]\n",
    "\n",
    "  #print('Accuracy: %.2f%%' % (accuracy * 100))\n",
    "  \n",
    "  return(accuracy * 100).mean()\n",
    "\n",
    "\n",
    "training_accuracy=get_acuuracy(rf, XtrainNew, Ytrain)\n",
    "print('Training accuracy: %.2f%%' %training_accuracy)\n",
    "\n",
    "test_accuracy=get_acuuracy(rf, XtestNew, Ytest)\n",
    "print('Test accuracy: %.2f%%' %test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAPTCHA prediction with Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 20, 20, 1)\n",
      "CAPTCHA TEXT: ['C' 'G' 'L' 'T']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADWElEQVR4nO3d207CQBRAUWr4/1+urwqRpnbY9LLWK4G0BXfG41SmeZ5vADS+Pn0AAFciugAh0QUIiS5ASHQBQqILELovPG4/GcB6018PWOkChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQjdP30A8AnTNP37ufM8DzwSrsZKFyAkugAh0QUImemGzBH34/F6bnlvYA0rXYCQ6AKERBcgZKY70Nq54Ks57eNrLb22me/7HPXaVnPqo16fT7HSBQiJLkDIeGGDkeOEvXrnr6hHvB5nMXLL3BV+Dkay0gUIiS5ASHQBQma6K11hG86rc1w6ri3PLV3htt8113vtjHfNdkd+s9IFCIkuQEh0AUJmum+0pxnmKyPnsEc5Z34bOYf1GXjNShcgJLoAIdEFCIkuQEh0AUKiCxASXYCQfboLzngf+RnPCY7CShcgJLoAIeMFnriNk0c+E+NY6QKERBcgJLoAITPdBSO/qvqM/EtAWMdKFyAkugAh0QUImem+0eO884wzyy0z7zNej9vtGF9D728Tn2OlCxASXYCQ6AKEzHRX+jmTWzsXO8qe1p/HufUr2PcyO9xyHHs5B87BShcgJLoAIdEFCJnpblDOL/eyv/OoRl4/e5HZwkoXICS6ACHRBQhNCzMnA6kLGDmjNO/cry1/c/BerfbnxbbSBQiJLkDIeIEnR7ldGXbMeAFgD0QXICS6ACG3AfPEHBbex0oXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXIHRfeHxKjgLgIqx0AUKiCxASXYCQ6AKERBcgJLoAoW//LYtX6vC1JAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cp = captcha_predict\n",
    "\n",
    "img = cv2.imread(\"tests/02.png\", 0)\n",
    "cp.rfPredict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#import metrics model to check the accuracy \n",
    "from sklearn import metrics\n",
    "#Running from k=1 through 5 and record testing accuracy\n",
    "k_range = range(1,5)\n",
    "scores = {}\n",
    "scores_list = []\n",
    "for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(XtrainNew,Ytrain)\n",
    "        y_pred=knn.predict(XtestNew)\n",
    "        scores[k] = metrics.accuracy_score(Ytest,y_pred)\n",
    "        scores_list.append(metrics.accuracy_score(Ytest,y_pred))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.9916169039963252,\n",
       " 2: 0.9873679375287092,\n",
       " 3: 0.9901240238860818,\n",
       " 4: 0.987827285254938}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Testing Accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_range,scores_list)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that there are 4 clusters, we will choose k=4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Setup a knn classifier with k neighbors'\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(XtrainNew,Ytrain)\n",
    "\n",
    "#Fitting the model\n",
    "knn.fit(XtrainNew,Ytrain)\n",
    "y_pred = knn.predict(XtestNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Accuracy of our KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.987827285254938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       266\n",
      "           1       1.00      0.99      0.99       269\n",
      "           2       1.00      0.98      0.99       263\n",
      "           3       0.99      0.97      0.98       278\n",
      "           4       1.00      0.99      1.00       279\n",
      "           5       0.99      0.98      0.99       293\n",
      "           6       0.99      0.99      0.99       256\n",
      "           7       1.00      1.00      1.00       327\n",
      "           8       1.00      1.00      1.00       267\n",
      "           9       1.00      0.97      0.99       233\n",
      "          10       1.00      0.99      0.99       251\n",
      "          11       1.00      0.99      0.99       265\n",
      "          12       1.00      0.97      0.99       283\n",
      "          13       0.99      1.00      0.99       271\n",
      "          14       1.00      0.99      0.99       268\n",
      "          15       1.00      1.00      1.00       301\n",
      "          16       0.99      0.99      0.99       274\n",
      "          17       1.00      0.98      0.99       292\n",
      "          18       1.00      0.99      0.99       290\n",
      "          19       1.00      0.99      0.99       248\n",
      "          20       1.00      0.99      1.00       306\n",
      "          21       1.00      0.99      0.99       269\n",
      "          22       0.97      0.99      0.98       196\n",
      "          23       1.00      0.99      0.99       260\n",
      "          24       1.00      0.98      0.99       310\n",
      "          25       1.00      0.99      1.00       283\n",
      "          26       1.00      0.99      0.99       281\n",
      "          27       1.00      0.99      0.99       273\n",
      "          28       1.00      0.98      0.99       212\n",
      "          29       1.00      0.98      0.99       264\n",
      "          30       0.99      1.00      1.00       319\n",
      "          31       1.00      0.98      0.99       261\n",
      "\n",
      "   micro avg       1.00      0.99      0.99      8708\n",
      "   macro avg       1.00      0.99      0.99      8708\n",
      "weighted avg       1.00      0.99      0.99      8708\n",
      " samples avg       0.99      0.99      0.99      8708\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmi/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "Accuracy=knn.score(XtestNew,Ytest)\n",
    "print('KNN Accuracy:',Accuracy)\n",
    "print(classification_report(Ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAPTCHA prediction with KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 20, 20, 1)\n",
      "CAPTCHA TEXT: ['C' 'G' 'L' 'T']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADWElEQVR4nO3d207CQBRAUWr4/1+urwqRpnbY9LLWK4G0BXfG41SmeZ5vADS+Pn0AAFciugAh0QUIiS5ASHQBQqILELovPG4/GcB6018PWOkChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQjdP30A8AnTNP37ufM8DzwSrsZKFyAkugAh0QUImemGzBH34/F6bnlvYA0rXYCQ6AKERBcgZKY70Nq54Ks57eNrLb22me/7HPXaVnPqo16fT7HSBQiJLkDIeGGDkeOEvXrnr6hHvB5nMXLL3BV+Dkay0gUIiS5ASHQBQma6K11hG86rc1w6ri3PLV3htt8113vtjHfNdkd+s9IFCIkuQEh0AUJmum+0pxnmKyPnsEc5Z34bOYf1GXjNShcgJLoAIdEFCIkuQEh0AUKiCxASXYCQfboLzngf+RnPCY7CShcgJLoAIeMFnriNk0c+E+NY6QKERBcgJLoAITPdBSO/qvqM/EtAWMdKFyAkugAh0QUImem+0eO884wzyy0z7zNej9vtGF9D728Tn2OlCxASXYCQ6AKEzHRX+jmTWzsXO8qe1p/HufUr2PcyO9xyHHs5B87BShcgJLoAIdEFCJnpblDOL/eyv/OoRl4/e5HZwkoXICS6ACHRBQhNCzMnA6kLGDmjNO/cry1/c/BerfbnxbbSBQiJLkDIeIEnR7ldGXbMeAFgD0QXICS6ACG3AfPEHBbex0oXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXIHRfeHxKjgLgIqx0AUKiCxASXYCQ6AKERBcgJLoAoW//LYtX6vC1JAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cp = captcha_predict\n",
    "\n",
    "img = cv2.imread(\"tests/02.png\", 0)\n",
    "cp.knnPredict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of KNN is satisfactory and the prediction is accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=\"7\"> Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are successful in implementing CAPTCHA recognition and prediction using Neural Networks on our dataset. We also trained and tested Random Forest and KNN classification algorithms. Both models had good accuracy of over 98%. Even though the accuracy was satisfactory in this case, both these algorithms become significantly slower as the volume of data increases making them an impractical choice in environments where predictions need to be made rapidly. Hence CNN emerges as the algorithm of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
